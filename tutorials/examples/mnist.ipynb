{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolvendo o MNIST com um Multilayer Perceptron (MLP)\n",
    "\n",
    "Exemplo simples de um experimento para resolver o MNIST. Visto que estamos executando em CPU, ele demora um tempo considerável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Type, Callable\n",
    "import enum\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchmetrics.classification import F1Score, Precision, Recall, Accuracy\n",
    "import torchvision.datasets as ds\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Ao definirmos os valores para essas variáveis de ambiente,\n",
    "#   conseguimos acessar os dados guardados no servidor remoto!\n",
    "os.environ['MLFLOW_TRACKING_URI']= \"http://<URL>:8080\"\n",
    "os.environ['MLFLOW_TRACKING_USERNAME']= \"<USER>\"\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD']= \"<PASSWORD>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, precisamos marcar essa célula com a tag \"parameters\"\n",
    "# https://papermill.readthedocs.io/en/latest/usage-parameterize.html\n",
    "\n",
    "experiment_name: str = 'tutorials/examples/mnist'\n",
    "run_name: str = 'mlp_variant_1'\n",
    "\n",
    "n_hidden: list[int] = [500]\n",
    "batch_size: int = 100\n",
    "epochs: int = 20\n",
    "loss_fn: str = 'CrossEntropyLoss'\n",
    "init: str = 'HE_NORMAL'\n",
    "optimizer: str = 'AdamW'\n",
    "lr: float = 0.001\n",
    "random_state = 27894018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções e classes utilitárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Initialization(enum.Enum):\n",
    "  ZEROES = nn.init.zeros_\n",
    "  UNIFORM = nn.init.uniform_\n",
    "  XAVIER_UNIFORM = nn.init.xavier_uniform_\n",
    "  XAVIER_NORMAL = nn.init.xavier_normal_\n",
    "  HE_UNIFORM = nn.init.kaiming_uniform_\n",
    "  HE_NORMAL = nn.init.kaiming_normal_\n",
    "\n",
    "\n",
    "class MLP:\n",
    "  def __init__(self,\n",
    "               n_input: int,\n",
    "               n_output: int,\n",
    "               n_hidden: list[int],\n",
    "               loss_fn,\n",
    "               batch_size: int = 64,\n",
    "               epochs: int = 100,\n",
    "               dropout_prob: list[float | None] = None,\n",
    "               output_fn: Callable[[], nn.Module] = None,\n",
    "               hidden_fn: Callable[[], nn.Module] = None,\n",
    "               init: Initialization = Initialization.XAVIER_NORMAL,\n",
    "               optimizer: Type[optim.Optimizer] = optim.SGD,\n",
    "               optimizer_params: dict = None):\n",
    "    # Set defaults\n",
    "    if dropout_prob is None:\n",
    "      dropout_prob = [None] * len(n_hidden)\n",
    "\n",
    "    if output_fn is None:\n",
    "      output_fn = lambda: nn.Softmax(dim=1)\n",
    "\n",
    "    if hidden_fn is None:\n",
    "      hidden_fn = nn.ReLU\n",
    "\n",
    "    if optimizer_params is None:\n",
    "      optimizer_params = dict(lr=0.001)\n",
    "\n",
    "    # Assertions\n",
    "    assert len(n_hidden) > 0\n",
    "    assert len(dropout_prob) == len(n_hidden)\n",
    "\n",
    "    # Input layer\n",
    "    layers = [nn.Flatten()]\n",
    "\n",
    "    # Hidden layers\n",
    "    for i in range(len(n_hidden)):\n",
    "      n_prev = n_input if i <= 0 else n_hidden[i - 1]\n",
    "      hidden_layer = [nn.Linear(n_prev, n_hidden[i], bias=True),\n",
    "                      hidden_fn()]\n",
    "      # Check whether we should add a dropout\n",
    "      #   layer or not\n",
    "      dropout = dropout_prob[i]\n",
    "      if dropout is not None:\n",
    "        hidden_layer.append(nn.Dropout(dropout))\n",
    "\n",
    "      # Extend layers with hidden layer\n",
    "      layers.extend(hidden_layer)\n",
    "\n",
    "    # Output layer\n",
    "    layers.extend((nn.Linear(n_hidden[-1], n_output, bias=True),\n",
    "                   output_fn()))\n",
    "\n",
    "    # Store variables\n",
    "    self._epochs = epochs\n",
    "    self._loss = loss_fn\n",
    "    self._batch_size = batch_size\n",
    "    self._signature = None\n",
    "\n",
    "    # Create MLP\n",
    "    self._mlp = nn.Sequential(*layers)\n",
    "\n",
    "    # Create optimizer\n",
    "    self._optim = optimizer(self._mlp.parameters(),\n",
    "                            **optimizer_params)\n",
    "\n",
    "    # Create error history\n",
    "    self._train_error = []\n",
    "    self._test_error = []\n",
    "\n",
    "    # Initialize weights\n",
    "    def init_weights(m):\n",
    "      if isinstance(m, nn.Linear):\n",
    "          init(m.weight)\n",
    "\n",
    "    self._mlp.apply(init_weights)\n",
    "\n",
    "  @property\n",
    "  def model(self) -> nn.Module:\n",
    "    return self._mlp\n",
    "\n",
    "  @property\n",
    "  def optimizer(self) -> optim.Optimizer:\n",
    "    return self._optim\n",
    "  \n",
    "  @property\n",
    "  def signature(self):\n",
    "    return self._signature\n",
    "\n",
    "  def fit(self,\n",
    "          train: torch.utils.data.Dataset,\n",
    "          test: torch.utils.data.Dataset) -> None:\n",
    "    # Create DataLoader from dataset\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train,\n",
    "                                               batch_size=self._batch_size,\n",
    "                                               pin_memory=True,\n",
    "                                               shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test,\n",
    "                                              batch_size=self._batch_size,\n",
    "                                              pin_memory=True,\n",
    "                                              shuffle=False)\n",
    "    # Start training\n",
    "    for _ in range(self._epochs):\n",
    "      total_loss = torch.tensor(0.0)\n",
    "      n = 0\n",
    "\n",
    "      # Set network to train mode\n",
    "      self._mlp.train()\n",
    "\n",
    "      # For each batch\n",
    "      for X, y in train_loader:\n",
    "        # Zero gradient for optimizer\n",
    "        self._optim.zero_grad()\n",
    "\n",
    "        # Predictions for current batch\n",
    "        predictions = self._mlp(X)\n",
    "\n",
    "        # Infer signature\n",
    "        if self._signature is None:\n",
    "          self._signature = infer_signature(\n",
    "            X.numpy(), predictions.detach().numpy())\n",
    "\n",
    "        # Loss for current batch\n",
    "        loss = self._loss(predictions, y)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimization step\n",
    "        self._optim.step()\n",
    "\n",
    "        # Update epoch loss\n",
    "        with torch.no_grad():\n",
    "          total_loss += loss\n",
    "          n += 1\n",
    "\n",
    "      # Obtain average loss over batches\n",
    "      total_loss = total_loss / n\n",
    "      self._train_error.append(total_loss)\n",
    "\n",
    "      # Set network to evaluation mode\n",
    "      self._mlp.eval()\n",
    "\n",
    "      # Obtain error in test set\n",
    "      total_loss = torch.tensor(0.0)\n",
    "      n = 0\n",
    "      for X, y in test_loader:\n",
    "        with torch.no_grad():\n",
    "          total_loss += self._loss(self._mlp(X), y)\n",
    "          n += 1\n",
    "\n",
    "      # Store test loss\n",
    "      total_loss = total_loss / n\n",
    "      self._test_error.append(total_loss)\n",
    "\n",
    "  def predict(self, X: torch.Tensor) -> torch.Tensor:\n",
    "    self._mlp.eval()\n",
    "    return self._mlp(X)\n",
    "\n",
    "  def train_metrics(self) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    train_error = torch.tensor(self._train_error)\n",
    "    test_error = torch.tensor(self._test_error)\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_error(model_name: str,\n",
    "                        train_error: torch.Tensor,\n",
    "                        test_error: torch.Tensor,\n",
    "                        metric_name: str = 'Error'):\n",
    "  train = [dict(Epoch=i, Error=v, Set='Treino')\n",
    "           for i, v in enumerate(train_error.numpy())]\n",
    "  test = [dict(Epoch=i, Error=v, Set='Teste')\n",
    "           for i, v in enumerate(test_error.numpy())]\n",
    "  df = pd.DataFrame(train + test)\n",
    "  fig = px.line(df,\n",
    "                x=\"Epoch\",\n",
    "                y=\"Error\",\n",
    "                color=\"Set\",\n",
    "                title=(f\"{metric_name} do \"\n",
    "                      f\"modelo {model_name} \"\n",
    "                      \"durante treinamento\"))\n",
    "  return fig\n",
    "\n",
    "\n",
    "def classification_metrics_df(model: MLP, test: torch.utils.data.Dataset):\n",
    "  # Obtain target and X\n",
    "  target = test.targets\n",
    "  X = test.data.detach().type(torch.FloatTensor)\n",
    "  n_classes = target.unique().size(dim=0)\n",
    "\n",
    "  # Obtain predictions\n",
    "  preds = model.predict(X)\n",
    "  _, preds = torch.max(preds, 1)\n",
    "  data = []\n",
    "\n",
    "  # Metrics\n",
    "  for avg in [None, 'weighted']:\n",
    "    for m in [F1Score, Precision, Recall, Accuracy]:\n",
    "      value = m(task=\"multiclass\",\n",
    "                num_classes=n_classes,\n",
    "                average=avg)(preds, target).numpy()\n",
    "      name = m.__name__\n",
    "\n",
    "      if not avg:\n",
    "        data.extend([dict(Class=str(i),\n",
    "                          Value=v,\n",
    "                          Metric=name)\n",
    "                     for i, v, in enumerate(value)])\n",
    "      else:\n",
    "        data.append(dict(Class='Weighted',\n",
    "                         Value=value,\n",
    "                         Metric=name))\n",
    "\n",
    "  # Create DataFrane\n",
    "  return pd.DataFrame(data).sort_values(by=[\"Class\", \"Metric\"])\n",
    "\n",
    "def plot_classification_metrics(model: MLP,\n",
    "                                test: torch.utils.data.Dataset,\n",
    "                                df=None):\n",
    "  if df is None:\n",
    "    df = classification_metrics_df(model, test)\n",
    "\n",
    "  fig = px.bar(df,\n",
    "                x='Class',\n",
    "                y='Value',\n",
    "                color='Metric',\n",
    "                title=\"Métricas de Classificação\",\n",
    "                barmode='group')\n",
    "  fig.update_layout(xaxis=dict(dtick=1))\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando split de treinamento\n",
    "train_dataset = ds.MNIST(root='../../data/',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "# Carregando o split de testes\n",
    "test_dataset = ds.MNIST(root='../../data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução dos Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando seeds randômicas\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/13 00:05:07 WARNING mlflow.utils.requirements_utils: Found torch version (2.1.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.1.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2023/12/13 00:05:10 WARNING mlflow.utils.requirements_utils: Found torch version (2.1.1+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.1.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    }
   ],
   "source": [
    "# Vamos criar um experimento com esse nome caso ele não exista\n",
    "# Primeiro, obtemos uma lista de experimentos com esse nome\n",
    "experiments = mlflow.search_experiments(\n",
    "    filter_string=f\"name = '{experiment_name}'\")\n",
    "\n",
    "# Caso não tenham sido encontrados experimentos, precisamos criar um novo\n",
    "if len(experiments) <= 0:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_name)\n",
    "else:\n",
    "    experiment_id = experiments[0].experiment_id\n",
    "\n",
    "# Vamos iniciar uma nova run para armazenar os resultados\n",
    "with mlflow.start_run(experiment_id=experiment_id,\n",
    "                      run_name=run_name) as run:\n",
    "\n",
    "    # Realizando o log de parâmetros e\n",
    "    #  hiper-parâmetros\n",
    "    mlflow.log_params({\n",
    "        'n_hidden': n_hidden,\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'loss_fn': loss_fn,\n",
    "        'init': init,\n",
    "        'optimizer': optimizer,\n",
    "        'lr': lr,\n",
    "        'random_state': random_state,\n",
    "        'train_samples': len(train_dataset),\n",
    "        'test_samples': len(test_dataset)\n",
    "    })\n",
    "\n",
    "    # Instanciando o classificador\n",
    "    mlp = MLP(n_input=784,\n",
    "              n_hidden=n_hidden,\n",
    "              n_output=10,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              loss_fn=getattr(nn, loss_fn)(),\n",
    "              init=getattr(Initialization, init),\n",
    "              optimizer=getattr(optim, optimizer),\n",
    "              optimizer_params=dict(lr=lr))\n",
    "\n",
    "    # Realizando treinamento do classificador\n",
    "    mlp.fit(train_dataset, test_dataset)\n",
    "\n",
    "    # Salvando modelo\n",
    "    mlflow.pytorch.log_model(mlp.model, \"mlp\", \n",
    "                             signature=mlp.signature)\n",
    "\n",
    "    # Obtendo as métricas de classificação\n",
    "    df = classification_metrics_df(mlp, test_dataset)\n",
    "    report = df[df['Class'] == 'Weighted'].to_dict('records')\n",
    "\n",
    "    # Salvando as métricas de classificação\n",
    "    for entry in report:\n",
    "        mlflow.log_metric(f\"Weighted {entry['Metric']}\",\n",
    "                          entry['Value'])\n",
    "\n",
    "    # Obtenção da figura do erro de treinamento\n",
    "    error_fig = plot_training_error('MLP', \n",
    "                                    *mlp.train_metrics(), \n",
    "                                    'Cross Entropy')\n",
    "\n",
    "    # Salvando imagem\n",
    "    error_fig.write_image('training_error.png')\n",
    "\n",
    "    # Salvando o artefato\n",
    "    mlflow.log_artifact('training_error.png')\n",
    "\n",
    "    # Removendo arquivos\n",
    "    os.remove('training_error.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
