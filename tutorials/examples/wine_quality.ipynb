{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolvendo o Wine Quality com Random Forest (RF)\n",
    "\n",
    "Exemplo simples resolvendo o dataset Wine Quality com um classificador Random Forest (RF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ao definirmos os valores para essas variáveis de ambiente,\n",
    "#   conseguimos acessar os dados guardados no servidor remoto!\n",
    "os.environ['MLFLOW_TRACKING_URI']= \"http://<URL>:8080\"\n",
    "os.environ['MLFLOW_TRACKING_USERNAME']= \"<USER>\"\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD']= \"<PASSWORD>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, precisamos marcar essa célula com a tag \"parameters\"\n",
    "# https://papermill.readthedocs.io/en/latest/usage-parameterize.html\n",
    "\n",
    "experiment_name: str = 'tutorials/example/wine_quality'\n",
    "run_name: str = 'rf_1'\n",
    "\n",
    "n_estimators: int = 10\n",
    "criterion: str = 'gini'\n",
    "max_depth: int | None = None\n",
    "bootstrap: bool = False\n",
    "oob_score: bool = False\n",
    "random_state = 27894018\n",
    "verbose: int = 0\n",
    "\n",
    "test_size: float = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções e Classes Utilitárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_fig(confusion: np.ndarray,\n",
    "                         classes: list[int] = list(range(1, 4)),\n",
    "                         pred_label='Modelo',\n",
    "                         true_label='Real',\n",
    "                         color_label=\"Quantidade\"):\n",
    "    \"\"\"Essa função retorna uma figura do Plotly representando\n",
    "    a matrix de confusão das predições recebidas como entrada.\n",
    "\n",
    "    Args:\n",
    "        confusion (np.ndarray): matriz de confusão das predições.\n",
    "        pred_label (str, optional): label usada para predições do modelo. Defaults to 'Modelo'.\n",
    "        true_label (str, optional): label usada para valores reais. Defaults to 'Real'.\n",
    "        color_label (str, optional): label usada para definir as cores. Defaults to \"Quantidade\".\n",
    "\n",
    "    Returns:\n",
    "        fig: figura do Plotly.\n",
    "    \"\"\"\n",
    "    fig = px.imshow(confusion,\n",
    "                    labels=dict(x=pred_label,\n",
    "                                y=true_label,\n",
    "                                color=color_label),\n",
    "                    x=classes,\n",
    "                    y=classes,\n",
    "                    text_auto=True)\n",
    "    fig.update_xaxes(side=\"top\")\n",
    "    fig.update_layout(xaxis={\n",
    "        'tickmode': 'array',\n",
    "        'tickvals': classes,\n",
    "    })\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def feature_importance_fig(etree,\n",
    "                           features_names: list[str]):\n",
    "    importance = etree.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in etree.estimators_], axis=0)\n",
    "    etree_importance = pd.DataFrame({\n",
    "        'Feature': features_names,\n",
    "        'Average Gini Importance': importance,\n",
    "        'std': std\n",
    "    })\n",
    "\n",
    "    fig = px.bar(etree_importance,\n",
    "                 x='Feature',\n",
    "                 y='Average Gini Importance',\n",
    "                 error_y='std')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset\n",
    "wine = datasets.load_wine()\n",
    "features = wine.data\n",
    "target = wine.target\n",
    "\n",
    "# Preparando os splits de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    target,\n",
    "                                                    test_size=test_size,\n",
    "                                                    stratify=target,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "# Criando datasets de treino e teste do mlflow\n",
    "ds_train = mlflow.data.from_numpy(X_train, targets=y_train)\n",
    "ds_test = mlflow.data.from_numpy(X_test, targets=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar um experimento com esse nome caso ele não exista\n",
    "# Primeiro, obtemos uma lista de experimentos com esse nome\n",
    "experiments = mlflow.search_experiments(\n",
    "    filter_string=f\"name = '{experiment_name}'\")\n",
    "\n",
    "# Caso não tenham sido encontrados experimentos, precisamos criar um novo\n",
    "if len(experiments) <= 0:\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_name)\n",
    "else:\n",
    "    experiment_id = experiments[0].experiment_id\n",
    "\n",
    "# Vamos iniciar uma nova run para armazenar os resultados\n",
    "with mlflow.start_run(experiment_id=experiment_id,\n",
    "                      run_name=run_name) as run:\n",
    "\n",
    "    # Realizando o log de parâmetros e\n",
    "    #  hiper-parâmetros\n",
    "    mlflow.log_params({\n",
    "        'n_estimators': n_estimators,\n",
    "        'criterion': criterion,\n",
    "        'max_depth': max_depth,\n",
    "        'bootstrap': bootstrap,\n",
    "        'oob_score': oob_score,\n",
    "        'random_state': random_state,\n",
    "        'verbose': verbose,\n",
    "        'train_samples': len(X_train),\n",
    "        'test_samples': len(X_test)\n",
    "    })\n",
    "\n",
    "    # Instanciando o classificador\n",
    "    clf = ExtraTreesClassifier(n_estimators=n_estimators,\n",
    "                               criterion=criterion,\n",
    "                               max_depth=max_depth,\n",
    "                               bootstrap=bootstrap,\n",
    "                               oob_score=oob_score,\n",
    "                               random_state=random_state,\n",
    "                               verbose=verbose)\n",
    "\n",
    "    # Realizando log dos dados de treinamento\n",
    "    mlflow.log_input(ds_train, context=\"training\")\n",
    "\n",
    "    # Realizando treinamento do classificador\n",
    "    clf.fit(ds_train.features, ds_train.targets)\n",
    "\n",
    "    # Salvando modelo\n",
    "    mlflow.sklearn.log_model(clf, \"extra_trees\")\n",
    "\n",
    "    # Realizando log dos dados de treinamento\n",
    "    mlflow.log_input(ds_test, context=\"testing\")\n",
    "\n",
    "    # Realizando predições para obter as métricas\n",
    "    y_pred = clf.predict(ds_test.features)\n",
    "\n",
    "    # Geração das métricas\n",
    "    cm = confusion_matrix(ds_test.targets, y_pred)\n",
    "    report = classification_report(y_test,\n",
    "                                   y_pred,\n",
    "                                   digits=3,\n",
    "                                   output_dict=True,\n",
    "                                   zero_division=0)\n",
    "\n",
    "    # Salvando as métricas de classificação\n",
    "    for k in report['weighted avg']:\n",
    "        mlflow.log_metric(k,\n",
    "                          report['weighted avg'][k])\n",
    "\n",
    "    # Obtenção da matriz de confusão\n",
    "    cm_fig = confusion_matrix_fig(cm)\n",
    "\n",
    "    # Salvando imagem\n",
    "    cm_fig.write_image('confusion_matrix.png')\n",
    "\n",
    "    # Salvando o artefato\n",
    "    mlflow.log_artifact('confusion_matrix.png')\n",
    "\n",
    "    # Obtenção da figura de importância das características\n",
    "    fi_fig = feature_importance_fig(clf,\n",
    "                                    wine.feature_names)\n",
    "\n",
    "    # Salvando imagem\n",
    "    fi_fig.write_image('feature_importance.png')\n",
    "\n",
    "    # Salvando o artefato\n",
    "    mlflow.log_artifact('feature_importance.png')\n",
    "\n",
    "    # Removendo arquivos\n",
    "    os.remove('confusion_matrix.png')\n",
    "    os.remove('feature_importance.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
